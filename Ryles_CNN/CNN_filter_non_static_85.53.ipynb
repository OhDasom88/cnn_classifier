{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import preprocessing \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24eddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_dataset = pd.read_csv('../DATA/train_spacing.csv')\n",
    "test_dataset = pd.read_csv('../DATA/test_spacing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289719d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 37.4 ms, total: 12 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pos(x):\n",
    "    try:\n",
    "        text = ''\n",
    "        for word, pos in mecab.pos(str(x)):\n",
    "            if pos[0] not in ['J','I','E']:\n",
    "                if type(re.search(\"\\W+|[0-9]\", word))!=re.Match: \n",
    "                    # and len(word)!=1:\n",
    "                    text+=\" \"+word\n",
    "        return text.strip()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "train_dataset[\"pos\"] = train_dataset[\"document\"].apply(pos)\n",
    "test_dataset[\"pos\"] = test_dataset[\"document\"].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0215befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = [] \n",
    "\n",
    "for line in train_dataset['pos']:\n",
    "    vocab_size.extend(str(line).split())\n",
    "vocab_size = len(set(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782f8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(train_dataset['pos'])\n",
    "word_index = tokenizer.word_index\n",
    "vocabulary_inv = tokenizer.index_word\n",
    "\n",
    "# padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = tokenizer.texts_to_sequences(train_dataset['pos'])\n",
    "test_seq = tokenizer.texts_to_sequences(test_dataset['pos'])\n",
    "train_pad = pad_sequences(train_seq, maxlen=40, padding='pre', truncating='pre')\n",
    "test_pad = pad_sequences(test_seq, maxlen=40, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cd51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "filter_sizes = (2, 3, 4, 5)\n",
    "num_filters = 100\n",
    "dropout = 0.5\n",
    "hidden_dims = 100\n",
    "\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "min_word_count = 1\n",
    "context = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351bafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be921fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = word2vec.Word2Vec.load(\"../DATA/ko.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c5484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_inv.update({0:'pad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d070986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2605901587.py:1: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  same_variance = np.var(embedding_model.syn1neg)\n"
     ]
    }
   ],
   "source": [
    "same_variance = np.var(embedding_model.syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730582b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2823837837.py:1: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n",
      "/var/folders/s5/j2ttz_bd7d500bsb_zg9212w0000gn/T/ipykernel_64557/2823837837.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = {key: embedding_model[word] if word in embedding_model else np.random.uniform(-same_variance, same_variance, embedding_model.vector_size) for key, word in vocabulary_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733276c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Flatten, Dropout\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54b57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2021)\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27050568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 40, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional block\n",
    "input_shape=(40, )\n",
    "conv_blocks = []\n",
    "\n",
    "model_input = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "z = keras.layers.Embedding(len(word_index)+1, embedding_dim, input_length=len(train_dataset['label']), name=\"embedding\")(model_input)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84658b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in filter_sizes:\n",
    "    conv = keras.layers.Conv1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"Same\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = keras.layers.MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = keras.layers.Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "    \n",
    "z = keras.layers.Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(512, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "# z = keras.layers.Dense(256, activation=\"relu\")(z)\n",
    "# z = keras.layers.Dropout(dropout)(z)\n",
    "z = keras.layers.Dense(128, activation=\"relu\")(z)\n",
    "z = keras.layers.Dropout(dropout)(z)\n",
    "model_output = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = keras.Model(model_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b2431b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e103fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 200)      9284600     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 40, 200)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 40, 100)      40100       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 40, 100)      60100       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 40, 100)      80100       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 40, 100)      100100      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 20, 100)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 20, 100)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 20, 100)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 20, 100)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2000)         0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2000)         0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2000)         0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2000)         0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8000)         0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8000)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          4096512     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65664       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,727,305\n",
      "Trainable params: 13,727,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2412a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with word2vec weights, shape (46423, 200)\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([v for v in embedding_weights.values()])\n",
    "print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "embedding_layer = model.get_layer(\"embedding\")\n",
    "embedding_layer.set_weights([weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a6aea61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "300/300 - 74s - loss: 0.7034 - accuracy: 0.5684 - val_loss: 0.5719 - val_accuracy: 0.7329\n",
      "Epoch 2/23\n",
      "300/300 - 73s - loss: 0.5332 - accuracy: 0.7330 - val_loss: 0.4629 - val_accuracy: 0.7991\n",
      "Epoch 3/23\n",
      "300/300 - 73s - loss: 0.4631 - accuracy: 0.7833 - val_loss: 0.4349 - val_accuracy: 0.8204\n",
      "Epoch 4/23\n",
      "300/300 - 73s - loss: 0.4271 - accuracy: 0.8054 - val_loss: 0.4028 - val_accuracy: 0.8299\n",
      "Epoch 5/23\n",
      "300/300 - 73s - loss: 0.4076 - accuracy: 0.8186 - val_loss: 0.4016 - val_accuracy: 0.8346\n",
      "Epoch 6/23\n",
      "300/300 - 73s - loss: 0.3916 - accuracy: 0.8279 - val_loss: 0.3899 - val_accuracy: 0.8386\n",
      "Epoch 7/23\n",
      "300/300 - 73s - loss: 0.3784 - accuracy: 0.8362 - val_loss: 0.3762 - val_accuracy: 0.8419\n",
      "Epoch 8/23\n",
      "300/300 - 73s - loss: 0.3670 - accuracy: 0.8419 - val_loss: 0.3696 - val_accuracy: 0.8452\n",
      "Epoch 9/23\n",
      "300/300 - 73s - loss: 0.3569 - accuracy: 0.8475 - val_loss: 0.3635 - val_accuracy: 0.8460\n",
      "Epoch 10/23\n",
      "300/300 - 73s - loss: 0.3489 - accuracy: 0.8515 - val_loss: 0.3565 - val_accuracy: 0.8481\n",
      "Epoch 11/23\n",
      "300/300 - 73s - loss: 0.3412 - accuracy: 0.8559 - val_loss: 0.3490 - val_accuracy: 0.8496\n",
      "Epoch 12/23\n",
      "300/300 - 73s - loss: 0.3346 - accuracy: 0.8583 - val_loss: 0.3489 - val_accuracy: 0.8503\n",
      "Epoch 13/23\n",
      "300/300 - 72s - loss: 0.3287 - accuracy: 0.8616 - val_loss: 0.3454 - val_accuracy: 0.8508\n",
      "Epoch 14/23\n",
      "300/300 - 73s - loss: 0.3212 - accuracy: 0.8657 - val_loss: 0.3424 - val_accuracy: 0.8516\n",
      "Epoch 15/23\n",
      "300/300 - 72s - loss: 0.3163 - accuracy: 0.8694 - val_loss: 0.3409 - val_accuracy: 0.8535\n",
      "Epoch 16/23\n",
      "300/300 - 72s - loss: 0.3090 - accuracy: 0.8718 - val_loss: 0.3418 - val_accuracy: 0.8532\n",
      "Epoch 17/23\n",
      "300/300 - 72s - loss: 0.3046 - accuracy: 0.8742 - val_loss: 0.3405 - val_accuracy: 0.8523\n",
      "Epoch 18/23\n",
      "300/300 - 73s - loss: 0.2996 - accuracy: 0.8775 - val_loss: 0.3392 - val_accuracy: 0.8540\n",
      "Epoch 19/23\n",
      "300/300 - 72s - loss: 0.2956 - accuracy: 0.8788 - val_loss: 0.3414 - val_accuracy: 0.8542\n",
      "Epoch 20/23\n",
      "300/300 - 72s - loss: 0.2908 - accuracy: 0.8807 - val_loss: 0.3388 - val_accuracy: 0.8539\n",
      "Epoch 21/23\n",
      "300/300 - 73s - loss: 0.2863 - accuracy: 0.8827 - val_loss: 0.3376 - val_accuracy: 0.8543\n",
      "Epoch 22/23\n",
      "300/300 - 73s - loss: 0.2829 - accuracy: 0.8853 - val_loss: 0.3390 - val_accuracy: 0.8544\n",
      "Epoch 23/23\n",
      "300/300 - 72s - loss: 0.2800 - accuracy: 0.8852 - val_loss: 0.3375 - val_accuracy: 0.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb84266d8b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad, train_dataset['label'], batch_size=500, epochs=23, validation_data=(test_pad, test_dataset['label']),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf18af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
